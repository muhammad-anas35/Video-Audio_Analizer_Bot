{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Instalation***"
      ],
      "metadata": {
        "id": "_AF5ktmgwIAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet google-genai"
      ],
      "metadata": {
        "id": "UhBOL-mnL1VW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install opencv-python speechrecognition numpy moviepy"
      ],
      "metadata": {
        "id": "zIRAPHMAYOQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a21e37b5-238f-46da-a463-19339c16c0b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.13.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Downloading SpeechRecognition-3.13.0-py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.13.0\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: speechrecognition in /usr/local/lib/python3.10/dist-packages (3.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (4.12.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.36.1)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Main Code***"
      ],
      "metadata": {
        "id": "wngZdH-3uA0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import files\n",
        "import speech_recognition as sr\n",
        "import moviepy.editor as mp\n",
        "from PIL import Image\n",
        "import requests\n",
        "import cv2\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=API_KEY)\n",
        "gpt_model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp-1219')\n",
        "\n",
        "def process_video(file_path):\n",
        "    try:\n",
        "        if file_path.startswith(\"http\"):\n",
        "            file_path = \"downloaded_video.mp4\"\n",
        "            with open(file_path, 'wb') as file:\n",
        "                file.write(requests.get(file_path).content)\n",
        "\n",
        "        video = cv2.VideoCapture(file_path)\n",
        "        if not video.isOpened():\n",
        "            return {\"error\": \"Failed to load video\"}\n",
        "\n",
        "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        frame_rate = int(video.get(cv2.CAP_PROP_FPS))\n",
        "        width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        audio_text = \"No audio\"\n",
        "        try:\n",
        "            video_clip = mp.VideoFileClip(file_path)\n",
        "            if video_clip.audio:\n",
        "                video_clip.audio.write_audiofile(\"audio.wav\")\n",
        "                with sr.AudioFile(\"audio.wav\") as source:\n",
        "                    audio_data = sr.Recognizer().record(source)\n",
        "                    audio_text = sr.Recognizer().recognize_google(audio_data)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        frame_descriptions = []\n",
        "        for frame_num in range(min(5, total_frames // frame_rate)):\n",
        "            video.set(cv2.CAP_PROP_POS_FRAMES, frame_num * frame_rate)\n",
        "            success, frame = video.read()\n",
        "            if success:\n",
        "                try:\n",
        "                    description = gpt_model.generate_content([\n",
        "                        \"Describe this video frame:\",\n",
        "                        Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "                    ]).text\n",
        "                    frame_descriptions.append(description)\n",
        "                except:\n",
        "                    frame_descriptions.append(\"Error processing frame\")\n",
        "\n",
        "        video.release()\n",
        "\n",
        "        os.remove(\"audio.wav\") if os.path.exists(\"audio.wav\") else None\n",
        "        if file_path == \"downloaded_video.mp4\":\n",
        "            os.remove(file_path)\n",
        "\n",
        "        return {\n",
        "            \"total_frames\": total_frames,\n",
        "            \"frame_rate\": frame_rate,\n",
        "            \"width\": width,\n",
        "            \"height\": height,\n",
        "            \"frame_descriptions\": frame_descriptions,\n",
        "            \"audio_text\": audio_text\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "def main():\n",
        "    uploaded_file = files.upload()\n",
        "    if not uploaded_file:\n",
        "        print(\"No file uploaded.\")\n",
        "        return\n",
        "\n",
        "    result = process_video(list(uploaded_file.keys())[0])\n",
        "    if \"error\" in result:\n",
        "        print(f\"Error: {result['error']}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Video Info: {result['total_frames']} frames, {result['frame_rate']} FPS, \"\n",
        "          f\"Dimensions: {result['width']}x{result['height']}\")\n",
        "    print(\"\\nFrame Descriptions:\")\n",
        "    for i, description in enumerate(result['frame_descriptions'], 1):\n",
        "        print(f\"Frame {i}: {description}\")\n",
        "    print(\"\\nAudio Transcript:\\n\", result['audio_text'])\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\n Enter 'exit' to close programme : \").lower()\n",
        "        if query == 'exit':\n",
        "            break\n",
        "\n",
        "        prompt = (\n",
        "            f\"Video Info: {result['total_frames']} frames, {result['frame_rate']} FPS, \"\n",
        "            f\"Dimensions: {result['width']}x{result['height']}. \"\n",
        "            f\"Frame Descriptions: {' '.join(result['frame_descriptions'])} \"\n",
        "            f\"Audio Transcript: {result['audio_text']} User Query: {query}\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            response = gpt_model.generate_content(prompt).text\n",
        "            print(\"\\nResponse:\", response)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "-0pey84Srogq",
        "outputId": "84942baa-ebd0-43f8-c2bf-4ebef2ba90a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3348266c-b808-4b68-b69c-79eadb9daae5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3348266c-b808-4b68-b69c-79eadb9daae5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving A Lone Traveler's Mysterious Discovery short part.mp4 to A Lone Traveler's Mysterious Discovery short part.mp4\n",
            "MoviePy - Writing audio in audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video Info: 688 frames, 30 FPS, Dimensions: 720x1280\n",
            "\n",
            "Frame Descriptions:\n",
            "Frame 1: The user wants me to describe a video frame. The frame contains the word \"If\" in the center of an otherwise completely black background. I should describe the text and the background.\n",
            "The video frame is entirely black except for the word \"If\" displayed in the center. The text is in a simple, sans-serif font and is a light gray color, contrasting against the dark background.\n",
            "Frame 2: The user wants a description of the video frame. I need to describe the scene, the objects, and the people/animals present in the frame. I will pay attention to the details and try to provide a comprehensive description.\n",
            "The video frame shows a person standing with a dog in what appears to be an abandoned or unfinished building. The environment is somewhat rough and industrial.\n",
            "\n",
            "In the foreground, the concrete floor is visible with some cracks and uneven surfaces.\n",
            "\n",
            "In the middle ground, a person with dark hair and wearing a black jacket over a white shirt, black pants, and white sneakers stands facing the viewer. The person has a leash in their hands, and a medium-sized, tan-colored dog stands beside them. The dog is also facing the viewer.\n",
            "\n",
            "Behind the person and the dog, there is an opening or doorway leading to an outdoor area with trees visible in the distance. The structure of the building has concrete pillars and beams. Some wooden boards appear to be part of the walls or structure in the background.\n",
            "\n",
            "The lighting in the frame suggests it's daytime, with natural light coming in from the opening. The upper part of the frame shows the concrete ceiling or upper level of the building, which also looks unfinished or aged.\n",
            "\n",
            "The word \"surprises\" is overlaid in white, bold font with a black outline, positioned roughly in the center of the frame, partially obscuring the background. The watermarks \"invideo/ali\" and \"iStock by Getty Images\" are also visible at the top and in the middle of the frame, respectively.\n",
            "Frame 3: The user wants a description of the video frame provided. The frame shows a person with a dog in what appears to be an abandoned building. I will describe the setting, the people/animals present and any notable details.\n",
            "The video frame shows a person and a dog standing in what appears to be the interior of an abandoned, possibly industrial, building. The lighting is somewhat dim, and the building looks weathered and aged. The ceiling is visible, showing a grid-like structure, and the walls and pillars appear to be made of concrete or a similar material. There are openings in the background, suggesting doorways or windows leading to the outside, where some greenery is visible.\n",
            "\n",
            "The person is standing in the center of the frame, facing the camera. They are wearing a black jacket, white shirt, and dark pants, with white sneakers. A brown dog is standing next to the person, its leash appearing to be held by the person's left hand. The floor is cracked and uneven.\n",
            "\n",
            "The word \"adventure,\" is superimposed on the image in a black, bold font, slightly obscuring the mid-section of the person. The top right corner has a logo that reads \"invideo/ali\" in white text against a purple background with a stylized fish icon.\n",
            "Frame 4: The user wants a description of the video frame. I need to describe the visual elements present in the image. I can see a person with a dog standing in what appears to be an abandoned building. There is text overlaid on the image.\n",
            "A low-angle shot depicts a person standing with a dog in the entryway of a dilapidated building. The building appears to be abandoned, with rough, unfinished concrete walls and ceilings. The floor is similarly rough and uneven.\n",
            "\n",
            "The person is seen from the knees up, wearing black pants, white shoes, and a black jacket over a white shirt. They are facing the camera but their face is not clearly visible. A brown, medium-sized dog stands beside them, facing the same direction.\n",
            "\n",
            "The entrance behind the person is bright, suggesting an outdoor area. The word \"yourself.\" is prominently overlaid in black, bold text in the middle of the frame, partially obscuring the view of the person. In the top right corner, the text \"invideo/ali\" is visible with a small, colorful logo next to it.\n",
            "Frame 5: The user wants a description of the provided video frame. I need to describe the objects, people, and the overall environment in the image. I should pay attention to details and be specific.\n",
            "A medium shot captures a person and a dog standing in the center of a dimly lit, dilapidated building. The building appears to be in a state of disrepair, with exposed concrete ceilings and support beams. Light filters in from an opening behind the person.\n",
            "\n",
            "The person is wearing a black jacket, dark pants, and white sneakers. They are standing facing the viewer. Next to the person is a medium-sized, short-haired brown dog.\n",
            "\n",
            "In the top right corner of the frame is a watermark that reads \"invideo/ali\". The word \"lone\" is superimposed in black and white across the center of the frame. The foreground shows a cracked and uneven concrete floor.\n",
            "\n",
            "Audio Transcript:\n",
            " if you don't like surprises but still crave Adventure then brace yourself alone traveler wanders through a ruined City they find a device that projects visions of a lost world suddenly it malfunctions memories blend hidden messages Flash and the environment shifts time is running out will they let go of the past or harness its power to reshape the future the choice is theirs but what would you do\n",
            "\n",
            " Enter 'exit' to close programme : exit\n"
          ]
        }
      ]
    }
  ]
}